{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绘制决策树学习曲线子函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 先抑制matplotlib的用户警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = UserWarning, module = \"matplotlib\")\n",
    "#\n",
    "# Display inline matplotlib plots with IPython\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 导入所需函数包\n",
    "import matplotlib.pyplot as pl\n",
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve, validation_curve #曲线绘制包\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split\n",
    "#ShuffleSplit也是拆分数据集的函数包,其产生指定数量的独立的train/test数据集划分数据集划分成n组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用不同大小的训练数据计算几个模型的性能，然后绘制每个模型的学习和验证分数\n",
    "def ModelLearning(X, y):\n",
    "    \"\"\" Calculates the performance of several models with varying sizes of training data.\n",
    "        The learning and validation scores for each model are then plotted. \"\"\"\n",
    "    \n",
    "    # Create 10 cross-validation sets for training and testing\n",
    "    # 产生10折交叉验证数据集，n_splits是将训练数据分成train/test对的组数，\n",
    "    cv = ShuffleSplit(n_splits = 10, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "    # Generate the training set sizes increasing by 50\n",
    "    #生成增加50的训练集\n",
    "    #np.rint计算数组各元素的四舍五入值\n",
    "    train_sizes = np.rint(np.linspace(1, X.shape[0]*0.8 - 1, 9)).astype(int)\n",
    "\n",
    "    # Create the figure window\n",
    "    # 创建显示窗口\n",
    "    fig = pl.figure(figsize=(10,7))\n",
    "    \n",
    "    # Create four different models based on max_depth\n",
    "    # 根据深度创建四种不同的模型\n",
    "    for k, depth in enumerate([1,3,6,10]):\n",
    "        \n",
    "        # Create a Decision tree regressor at max_depth = depth\n",
    "        # 创建决策树回归器\n",
    "        regressor = DecisionTreeRegressor(max_depth = depth)\n",
    "\n",
    "        # Calculate the training and testing scores\n",
    "        # 计算训练和验证分数\n",
    "        sizes, train_scores, valid_scores = learning_curve(regressor, X, y, \\\n",
    "            cv = cv, train_sizes = train_sizes, scoring = 'r2')\n",
    "        #  输入：estimator : 你用的分类器； title : 表格的标题；\n",
    "        #       X : 输入的feature，numpy类型；y : 输入的target vector\n",
    "        #       ylim : tuple格式的(ymin, ymax), 设定图像中纵坐标的最低点和最高点\n",
    "        #       cv : 做cross-validation的时候，数据分成的份数，其中一份作为cv集，其余n-1份作为training(默认为3份)\n",
    "        #        n_jobs : 并行的的任务数(默认1)\n",
    "        #  输出：train_sizes_abs :训练样本数，train_scores:训练集上准确率；test_scores:交叉验证集上的准确率   \n",
    "        \n",
    "        # Find the mean and standard deviation for smoothing\n",
    "        # 查找平滑的均值和标准偏差\n",
    "        train_std = np.std(train_scores, axis = 1)\n",
    "        train_mean = np.mean(train_scores, axis = 1)\n",
    "        valid_std = np.std(valid_scores, axis = 1)\n",
    "        valid_mean = np.mean(valid_scores, axis = 1)\n",
    "        \n",
    "        # Subplot the learning curve \n",
    "        # 绘制曲线\n",
    "        # fill_between是颜色充填函数\n",
    "        ax = fig.add_subplot(2, 2, k+1)\n",
    "        ax.plot(sizes, train_mean, 'o-', color = 'r', label = 'Training Score')\n",
    "        ax.plot(sizes, valid_mean, 'o-', color = 'g', label = 'Validation Score')\n",
    "        ax.fill_between(sizes, train_mean - train_std, \\\n",
    "            train_mean + train_std, alpha = 0.15, color = 'r')\n",
    "        ax.fill_between(sizes, valid_mean - valid_std, \\\n",
    "            valid_mean + valid_std, alpha = 0.15, color = 'g')\n",
    "        \n",
    "        # Labels\n",
    "        # set_xlim是x轴设置范围\n",
    "        ax.set_title('max_depth = %s'%(depth))\n",
    "        ax.set_xlabel('Number of Training Points')\n",
    "        ax.set_ylabel('r2_score')\n",
    "        ax.set_xlim([0, X.shape[0]*0.8])\n",
    "        ax.set_ylim([-0.05, 1.05])\n",
    "        \n",
    "    # Visual aesthetics\n",
    "    # 美化\n",
    "    ax.legend(bbox_to_anchor=(1.05, 2.05), loc='lower left', borderaxespad = 0.)\n",
    "    fig.suptitle('Decision Tree Regressor Learning Performances', fontsize = 16, y = 1.03)\n",
    "    fig.tight_layout()#紧凑图片，居中显示\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型复杂度曲线\n",
    "def ModelComplexity(X, y):\n",
    "    \"\"\" Calculates the performance of the model as model complexity increases.\n",
    "        The learning and validation errors rates are then plotted. \"\"\"\n",
    "    \n",
    "    # Create 10 cross-validation sets for training and testing\n",
    "    cv = ShuffleSplit(n_splits = 10, test_size = 0.2, random_state = 0)\n",
    "\n",
    "    # Vary the max_depth parameter from 1 to 10\n",
    "    max_depth = np.arange(1,11)\n",
    "\n",
    "    # Calculate the training and testing scores\n",
    "    train_scores, valid_scores = validation_curve(DecisionTreeRegressor(), X, y, \\\n",
    "        param_name = \"max_depth\", param_range = max_depth, cv = cv, scoring = 'r2')\n",
    "\n",
    "    # Find the mean and standard deviation for smoothing\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    valid_mean = np.mean(valid_scores, axis=1)\n",
    "    valid_std = np.std(valid_scores, axis=1)\n",
    "    \n",
    "    # Plot the validation curve\n",
    "    pl.figure(figsize=(7, 5))\n",
    "    pl.title('Decision Tree Regressor Complexity Performance')\n",
    "    pl.plot(max_depth, train_mean, 'o-', color = 'r', label = 'Training Score')\n",
    "    pl.plot(max_depth, valid_mean, 'o-', color = 'g', label = 'Validation Score')\n",
    "    pl.fill_between(max_depth, train_mean - train_std, \\\n",
    "        train_mean + train_std, alpha = 0.15, color = 'r')\n",
    "    pl.fill_between(max_depth, valid_mean - valid_std, \\\n",
    "        valid_mean + valid_std, alpha = 0.15, color = 'g')\n",
    "    \n",
    "    # Visual aesthetics\n",
    "    pl.legend(loc = 'lower right')\n",
    "    pl.xlabel('Maximum Depth')\n",
    "    pl.ylabel('r2_score')\n",
    "    pl.ylim([-0.05,1.05])\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行拟合和预测数据的试验\n",
    "def PredictTrials(X, y, fitter, data):\n",
    "    \"\"\" Performs trials of fitting and predicting data. \"\"\"\n",
    "\n",
    "    # Store the predicted prices\n",
    "    prices = []\n",
    "\n",
    "    for k in range(10):\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \\\n",
    "            test_size = 0.2, random_state = k)\n",
    "        \n",
    "        # Fit the data\n",
    "        reg = fitter(X_train, y_train)\n",
    "        \n",
    "        # Make a prediction\n",
    "        pred = reg.predict([data[0]])[0]\n",
    "        prices.append(pred)\n",
    "        \n",
    "        # Result\n",
    "        print \"Trial {}: ${:,.2f}\".format(k+1, pred)\n",
    "\n",
    "    # Display price range\n",
    "    print \"\\nRange in prices: ${:,.2f}\".format(max(prices) - min(prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
